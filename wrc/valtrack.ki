import graph;
import valstate;

struct vt_track {
  current vt_state;

  // Indexed by gr_num.
  annot array[vt_annot];
}

func mk_track(gr *frame_graph) vt_track {
  return {
    @[vt_state]{ },
    repeat(count(&gr->ops), {None})
  };
}

struct vt_annot {
  savestate opt[vt_state];
}

struct cgt {
  clq *clqueue;
  gr *frame_graph;
  track *vt_track;
}

func ensure_def_inst_valtracked(clq *clqueue, ent_id def_entry_id, inst_id def_inst_id) np {
  #ensure_def_inst_graphed(clq, ent_id, inst_id);
  #vt_regraphed(clq, un(&ref_inst(clq->cs, inst_id)->graph));
  return NoFail;
}

func vt_regraphed(clq *clqueue, gr *frame_regraphed) np {
  // TODO()
  return NoFail;
}

func vt_graph(clq *clqueue, gr *frame_graph, gn gr_num) np {
  // This uses a different traversal algorithm than some other graph-traversing code.  Metadata that tells us about the AST's structure make us revisit alternate branches more "locally," and more importantly, in a defined order that can be described in terms of the original AST.

  track vt_track = mk_track(gr);

  return vt_inner_expr({clq, gr, &track}, gn);
}

func vt_inner_expr(c cgt, gn gr_num) np {
  new_gn gr_num = #vt_xops(c, gn);
  // TODO()
  return NoFail;
}

func vt_xops(c cgt, gn gr_num) cr[gr_num] {
  for ;; {
    switch ref_node(c.gr, gn) {
    case &XOp(xn gr_xnode):
      // We should be chasing a qop chain.
      ice(_u8("vt_xops sees an xop."));
    case &QOp(qn gr_qnode):
      if qn.indegree.x > 1 {
        if Stale == #unify_vt_state(&ref(&c.track->annot, gn.x)->savestate, &c.track->current) {
          return NoFail(gn);
        }
      }
      switch &qn.op {
      case &GrBranch(a gr_branch):
        return NoFail(gn);  // TODO()
      case &GrSequence(a gr_sequence):
        #vt_single_xop(c, a.first);
        gn = a.second.x;
        // loop around
      case &GrJmp(a gr_jmp):
        switch a.disposition {
        case JmpForward:
          gn = a.next.x;
        case ExitNormalcy(b gr_jmp_exit_normalcy):
          saved_state vt_state = c.track->current;
          #vt_abnormal_excursion(c, a.next.x);
          c.track->current = saved_state;
          gn = b.subsequent_normalcy.x;
          // loop around
        case ReenterNormalcy:
          ice(_u8("vt_xops sees GrJmp ReenterNormalcy"));
        }
      case &GrQNop:
        return NoFail(gn);
      }
    }
  }
}

func vt_abnormal_excursion(c cgt, gn gr_num) np {
  for ;; {
    switch ref_node(c.gr, gn) {
    case &XOp(xn gr_xnode):
      ice(_u8("vt_abnormal_excursion sees a xop."));
    case &QOp(qn gr_qnode):
      // Abnormal excursions could merge together, yes.
      if qn.indegree.x > 1 {
        if Stale == #unify_vt_state(&ref(&c.track->annot, gn.x)->savestate, &c.track->current) {
          return NoFail;
        }
      }
      switch &qn.op {
      case &GrBranch(a gr_branch):
        ice(_u8("vt_abnormal_excursion sees a branch"));
      case &GrSequence(a gr_sequence):
        #vt_single_xop(c, a.first);
        gn = a.second.x;
      case &GrJmp(a gr_jmp):
        switch a.disposition {
        case JmpForward:
          gn = a.next.x;
        case ExitNormalcy(b gr_jmp_exit_normalcy):
          ice(_u8("vt_abnormal_excursion sees an ExitNormalcy"));
        case ReenterNormalcy:
          // TODO(): If not stale, we need to create a "to-retrack-from" marking.
          fr freshness = #unify_vt_state(&ref(&c.track->annot, a.next.x.x)->savestate, &c.track->current);
          return NoFail;
        }
      case &GrQNop:
        ice(_u8("vt_abnormal_excursion sees a QNop (is it final_node?)"));
      }
    }
  }
}

func vt_single_xop(c cgt, gn gr_num) np {
  switch ref_node(c.gr, gn) {
  case &XOp(xn gr_xnode):
    // We track the state modification of the XOp.  Which means we do nothing, because vt_state is an empty struct right now.
    return NoFail;
  case &QOp(qn gr_qnode):
    // Ack -- we've gotta trace a sub-qop-expr.
    return vt_inner_expr(c, gn);
  }
}
